# Лекция 8

## Алгоритмы планирования, применительно к конкретным реализациям в операционных системах

---

## Задача: 
* Поддержка внешнего управления приоритетами
* Эффективное использование ресурсов
* Минимальные накладные расходы
* Минимальные риски возникновения тупиков
  * Тупик - возникает, когда есть кольцевое ожидание процессов
    * Процесс п0 взял ресурс р0
    * Процесс п1 взял ресурс р1
    * Процессам необходимо перехватить ресурсы не теряя свои исходные ресурсы, таким образом получается тупик, заключающийся в том, что мы не можем получить ресурсы
    * __Это мы подробнее разберем на следующих лекциях__
  * Может возникнуть другой виду тупика
    * Есть два процесса р1 и р0
    * Есть всего 1 ресурс
    * У процесса р0 приоритет выше
    * р1 родился раньше, и уже использует ресурс
    * В какой-то момент родился процесс р0 и захотел ресурс, который сейчас на р1
    * Происходит тупик
## Решения

---

* Поддержка внешнего управления приоритетами
  * Сделать многоуровневую очередь и возможность классифицировать процесс в определенную группу
* Эффективное использование ресурсов
  * Shortest Job First (SJF)
  * Мы хотели бы сделать изменяемые непрервыные кванты выполнения
    * Потому что нам хотелось бы минимизировать количество переходов между процессами
  * Хотелось бы попадать в кэш, соответсвенно, иметь различные очереди, где мы можем перемещать наши процессы
* Минимальные накладные расходы
  * Целочисленная арифметика
  * В худшем случае мы хотим, чтобы наши алгоритмы работали за О(n)
  * Хотим, чтобы структуры данных в памяти были разумные по занимаемому объему
* Минимальные риски возникновения тупиков
  * Использование гарантированного планирования
    * Сама по себе справедливость не имеет никакого значения
    * Справедливость нужна для того, чтобы было меньше шансов задержать ресурсы в процессоре, а значит мы избежим тупика, связанного со взятием ресурсов более приоритетными процессами

---

## Разговор о конкретных реализациях алгоритмов в конкретных операционных системах

---

### Windows
### Внешнее управление приоритетами процессов
> Основывается на идее многоуровневых очередей
* Их 32
* Чем больше номер очереди тем выше приоритет
* Если несколько процессов находится в той или инной очереди, то между собой такие проецссы переключаются на основе алгоритма Round Robin
* Самая верхняя часть очереди с 1 по 16 - __Real time processes__
  * Процесс никогда никуда не переместится в очереди операционной системой
* Самая нижняя часть очереди с 0 по 15 - __Dynamic time processes__
  * Операционная система может менять очереди для процессов
  * Процесс, когда ему меняют приоритет, оне не может выйти за пределы своей группы
* Самая низкая очереди - 0 очередь, очередь обнуления страниц в памяти
  * Зачем это нужно ?
    * Когда процесс завершается, мы осводождаем адресное пространство, но данные этого процесса там остались
    * И если мы выделяем время другому процессу, то данные эти этот процесс можем прочитать. Это могут быть какие-то конфедициальные данные. Тогда можно написать вредоносную программу, которая будет завершать процессы и искать, нет ли чего-то полезного в оставшихся данных. 
|Queue number|---------|
|------------|---------|
|31||
|...||
|...||
|...||
|16||
|15||
|...||
|...||
|...||
|1||
|0||

#### Есть 6 классов приоритетов процессов
* Real time - 24 queue
* High - 13 queue
* Above normal - 10 queue
* Normal - 8 queue
* Below normal - 6 queue
* Idle - 4 queue
> То есть процессы, создаваясь, по умолчанию попадают в одну из этих очередей и имеют заданный приоритет. Но в процессе алгоритма планирования операционной системой этих процессов, процессы могут прыгать из одной очереди в другую

* Обычный непривелигированный пользователь не можем поставить свой процесс Real time queue
  * Но пользователь с правами доступа администратора может засунуть процесс в Real time queue

> Все процессы как правило помещаются в normal очередь

* Процесс - это еще и множество потоков
  * Таким образом планировщик по сути еще и управляет потоками  
  * И это тоже может быть внешне управляемым

#### Уровни насыщения
* Time critical +15
* Highest +2
* Above normal +1
* Normal ± 0
* Below normal -1
* Lowest -2
* Idle -15

* В чем идея уровней насыщения?
  * Мы выставляем для процессам класс в очереди
  * Когда будет выполняться код, для конкретного потока в процессе можно будет задать класс насыщения
  * Все уровни кроме Time critical и Idle
    * Не позволяют выйти выше своей очереди
  * В Time critical и Idle
    * можно менять уровень насыщения
  * Но Time critical и Idle при смене своего уровня насыщения не могут выходить за пределы группы, в которой они состоят (Real time и Dynamic time)

## Внутреннее управление приоритетами процессов
### Как оно устроено ?
* Операционная система для динамических приоритетов может их менять в зависимости от того, как изменился статус процесса после их выполнения
* Когда она можем менять приоритет ?
  * Вышел после дисковой опреации, приоритет увеличился на 1
  * Вернулся с полседоватеьлной опреации на порте, приоритет увеличился на 2
  * Вернулся с клавиатуры, приоритет увеличился сразу на 6 (для обеспечения времени отклика)
  * Для звукового процессора, приоритет увеличился на 8
  * И так далее...

> Эти изменения делаются не вечно
* В Windows вводится понятие кванта, которые вычисляется через таймер
  * Соответственно, процесс получил на 2 кванта жить в приориттеной очереди
  * И Если он не испольщовал полностью этот квант(например ушел в ожидание). То он может продолжить выполнение в это очереди оставшееся количество квантов.
  * Если он не ушел в ожидание и потратил все кванты 
    * Мы его вкидываем на очередь ниже и так далее до самого низа
* В Windows процесс может быть в низкоприоритетной очереди, что может вызвать голодание этого процесса. 
  * В Windows пошли путем создания специального компонента, который понимает, что какой-то процесс ждет боле 4 секунд
    * Если процесс ждет больше 4 секунд, ему на 1 квант даем сразу 15 очередь, чтобы он мог разгрузиться;
    * Это сделано для того, чтобы минимизировать возможность тупика

---

### Linux 
### Внешнее управление приоритетами процессов

> До 2.6 в Linux использовался планировщик, который работал за O(n)
#### Его идея
* У нас было n процессов, они были упорядочены по определенному признаку
* Выбирался процесс с наилучшим признаком
* В худшем случае, нужно было перебирать все значения признаков за колиство процессов

#### При появлении Java стали появляться многопоточные программы
Таким образом алгоритм за О(n) стал очень плохо работать в связи с тем, что в одном процессе могли быть сотни потоков, которые нужно было перебирать

#### Появился планировщик, который назывался O(1)
> Работал он за константу

* Каждый центральный процессор для планировщика O(1) представлен в виде многоуровневой очереди со 140 очередями
* В Linux все наоборот относительно Windows, очереди с менеьше номером имеют больий приоритет

|Queue number|smth|
|------------|----|
|1||
|...||
|...||
|...||
|100||
|101||
|...||
|...||
|...||
|140||

* Тут такая же идеология как и в Windows
  * Real time
  * Dynamic time
  * В Linux мы не можем за счет прав рута вывести пользовательский процесс в Real time
* Пользователь может в любой очереди менят приоритет своего процесса
  * Есть значение nice от -20 до +19
* Внутри очередей процессы живут в рамках Round Robin
* Квант выполнения зависит от значения nice в определенной очереди
  * Например при значении nice равным -20 мы можем дать очереди 200мс
  * При nice = 19, мы можем дать 10мс

##### Что произойдет с процессом, когда мы дадим ему выполниться ?
* У нас по факту есть 2 группы очередей, они одинаковы (__Active и Non Active__)
* Процессу отведем определенный квант времени
  * Если процесс сам ушел в ожидание(не потратив весь квант времени)
    * Он вернется и встанет в конец очереди
  * Если процесс выполнялся и потратил весь квант времени
    * Тогда мы помещаем его во 2 таблицу
      * Постепенно все процессы будут уходить во 2 очередь 
|Queue number|queue|     |Queue number|queue| 
|------------|-----|-----|------------|-----|
|1           |     |     |1           |     |
|...         |     |     |...         |     |
|...         |     |     |...         |     |
|...         |     |     |...         |     |
|100         |     |     |100         |     |
|101         |     |     |101         |     |
|...         |     |     |...         |     |
|...         |     |     |...         |     |
|...         |     |     |...         |     |
|140         |     |     |140         |     |

##### Это гарантирует нам отсутствие голодания
> Потому что рано или поздно все процессы уйдут во 2 очередь, а значит получат свой квант времени на выполнение
##### С другой стороны, выделяя кванты разного времени, мы даем возможность нетребовательным процессам получатьт меньше процессорного времени

### В более старщих версиях этого планировщика появилась возможность
* Если совападает, что процесс высокоприоритетный и еще и сильно интерактивный
  * Даже, когда он заканчивает свое выполнение, мы возвращаем процесс в конец этой же очереди
* Для обеспечения такого планирования вводится еще 1 коэфицент
  * Он оценивает то, что если мы будем разрешать процессу возвращатсья в ту же самую очередь, не приведет ли это к тому, что те процессы, которые ждут во 2 очереди.
  * И если коэффицент этого процесса будет выше какого-то порога, то мы скажем процессу, что в этот раз он должен будет уйти уже во 2 очередь

##### Поэтому мы гарантируем, что все процессы из 1 очереди попадут во 2
  * И когда это произойдет, мы просто поменяем указатели этих очередей, то есть свопнем их

##### Еще несколько вариантов, которые реализуются в этом планировании
* Для того, чтобы быстро находить очередь, в которой есть хоть один процесс, хранится битовый вектор размером в 140 бит, где если в этой очереди есть процесс, бит равен нулю и наоборот
* Таким образом, поиск следующего процесса на выполнение обеспечивается за счет поиска ближайшего не равного нулю бита в этой очереди
* Отсюда и название этого алгоритма

#### Возникла еще 1 проблема
> Если у нас будет достаточно приоритетный процесс, который будет постоянно порождать потоки, то эти потоки будут занимать верх приоритета очередей, что вызовет голодание более низкоприоритетных процессов
#### Придумали простую вещь
> Когда процесс порождает своего потомка, оставшееся время они делят пополам

#### Основная проблема этого алгоритма планирования
* Мы тратим накладные расходы на расчет коэффицента интерактивности

#### Появилась идея
* Использование гарантийного планирования (на основе его)
* Мы вводим 2 величины
  * execution_time
  * max_execution_time
* Когда процесс выполняется, мы увеличиваем его execution time
* max_execution_time для каждого процесса выводится для каждого процесса так, чтобы все было максимально справедливо
  * По сути это время ожидания деленое на колчиество процессов
* В каждый момент времени мы имеем массив, который упорядочен по execution_time
  * Каждый раз мы выбираем тот процесс, который меньше всего исполнялся. Даем ему возможность исполняться max_execution_time
  * Если он сам ушел в ожидание
    * Его execution_time стал меньше чем у тех, которые выполнялись в тот момент, когда он ждал
    * Таким образом этому процессу дадут сразу выполняться по возращении
  * Если процес довыполнил свой max_execution_time
    * Мы вынимаем самый левый процесс и смотрим сколько у max_execution_time по савнению с остальными
    * И ставим этот процесс в определенное место относительно этого параметра 

#### Как в такой модели изменять внешний приоритет
* Через изменение скорости, с которой вычисляется max_excution_time

Но как обеспечить скорость ? Ведь в таком случае нам нужно за O(n) искать куда вставить max_excution_time.
> Решили использовать красное черное дерево, что обеспечивает вставку и удаление за O(Log()n)
> Таким образом мы храним указатель на самый левый элемент дерева (самый маленький), это обеспечивает нам доступ за O(1)

Финальный планировщик называется __CFS__

#### Много процессорность и многопоточность
> Каждые 200 секунд мы перестраиваем процессы в очередях, перенося их с одного процессора на другой